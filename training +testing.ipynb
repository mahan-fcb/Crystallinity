{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d18d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##General imports\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import copy\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import platform\n",
    "\n",
    "##Torch imports\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader, Dataset\n",
    "from torch_geometric.nn import DataParallel\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import process\n",
    "def train(model, optimizer, loader, loss_method, rank):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    count = 0\n",
    "    for data in loader:\n",
    "        data = data.to(rank)\n",
    "        optimizer.zero_grad()\n",
    "        out_put = model(data)\n",
    "        # print(data.y.shape, output.shape)\n",
    "        loss = getattr(F, loss_method)(out_put, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.detach() * out_put.size(0)\n",
    "\n",
    "        # clip = 10\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "        optimizer.step()\n",
    "        count = count + out_put.size(0)\n",
    "\n",
    "    loss_all = loss_all / count\n",
    "    return loss_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad66a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = {  \n",
    "       \"out_dims\":4,\n",
    "        \"d_model\":512,\n",
    "        \"N\":3,\n",
    "        \"heads\":4,\n",
    "        #compute_device=None,\n",
    "        \"residual_nn\":'roost'\n",
    "        ,\"dim1\": 64\n",
    "        ,\"dim2\": 4\n",
    "        ,\"pre_fc_count\": 1\n",
    "        ,\"gc_count\": 10\n",
    "        ,\"post_fc_count\": 1\n",
    "        ,\"pool\": \"global_add_pool\"\n",
    "        ,\"pool_order\": \"early\"\n",
    "        ,\"batch_norm\": \"True\"\n",
    "        ,\"batch_track_stats\": \"True\"\n",
    "        ,\"act\": \"softplus\"\n",
    "        ,\"model\": \"DEEP_GATGNN\"\n",
    "        ,\"dropout_rate\": 0.0\n",
    "        ,\"epochs\": 300\n",
    "        ,\"lr\": 0.005\n",
    "        ,\"batch_size\": 90\n",
    "        ,\"optimizer\": \"AdamW\"\n",
    "        ,\"optimizer_args\": {}\n",
    "        ,\"scheduler\": \"ReduceLROnPlateau\"\n",
    "        ,\"scheduler_args\": {\"mode\":\"min\", \"factor\":0.8, \"patience\":10, \"min_lr\":0.00001, \"threshold\":0.0002}}\n",
    "training_parameters = { \n",
    "    \"target_index\": 0\n",
    "    #Loss functions (from pytorch) examples: l1_loss, mse_loss, binary_cross_entropy\n",
    "    ,\"loss\": \"l1_loss\"       \n",
    "    #Ratios for train/val/test split out of a total of 1  \n",
    "    ,\"train_ratio\": 0.8\n",
    "    ,\"val_ratio\": 0.05\n",
    "    ,\"test_ratio\": 0.15\n",
    "    #Training print out frequency (print per n number of epochs)\n",
    "    ,\"verbosity\": 1}\n",
    "job_parameters= { \n",
    "        \"reprocess\":\"False\"\n",
    "        ,\"job_name\": \"my_train_job\"\n",
    "        #model: CGCNN_demo   \n",
    "        ,\"load_model\": \"False\"\n",
    "        ,\"save_model\": \"True\"\n",
    "        ,\"model_path\": \"my_model.pth\"\n",
    "        ,\"write_output\": \"True\"\n",
    "        ,\"parallel\": \"True\"\n",
    "        #seed=0 means random initalization\n",
    "        ,\"seed\": 42\n",
    "        #job_name: \"my_CV_job\"\n",
    "        #reprocess: \"False\"    \n",
    "        #model: CGCNN_demo   \n",
    "        #write_output: \"True\"\n",
    "        #parallel: \"True\"\n",
    "        #seed: 0     \n",
    "        ###specific options\n",
    "        #number of folds for n-fold CV\n",
    "        ,\"cv_folds\": 5}\n",
    "Predict= {\n",
    "        \"job_name\": \"my_predict_job\"   \n",
    "        ,\"model_path\": \"my_model.pth\"\n",
    "        ,\"write_output\": \"True\"\n",
    "        ,\"seed\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7748715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, model, loss_method, rank, out=False):\n",
    "    model.eval()\n",
    "    loss_all = 0\n",
    "    count = 0\n",
    "    for data in loader:\n",
    "        data = data.to(rank)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            loss = getattr(F, loss_method)(output, data.y)\n",
    "            loss_all += loss * output.size(0)\n",
    "            if out == True:\n",
    "                if count == 0:\n",
    "                    ids = [item for sublist in data.structure_id for item in sublist]\n",
    "                    ids = [item for sublist in ids for item in sublist]\n",
    "                    predict = output.data.cpu().numpy()\n",
    "                    target = data.y.cpu().numpy()\n",
    "                else:\n",
    "                    ids_temp = [\n",
    "                        item for sublist in data.structure_id for item in sublist\n",
    "                    ]\n",
    "                    ids_temp = [item for sublist in ids_temp for item in sublist]\n",
    "                    ids = ids + ids_temp\n",
    "                    predict = np.concatenate(\n",
    "                        (predict, output.data.cpu().numpy()), axis=0\n",
    "                    )\n",
    "                    target = np.concatenate((target, data.y.cpu().numpy()), axis=0)\n",
    "            count = count + output.size(0)\n",
    "\n",
    "    loss_all = loss_all / count\n",
    "\n",
    "    if out == True:\n",
    "        test_out = np.column_stack((ids, target, predict))\n",
    "        return loss_all, test_out\n",
    "    elif out == False:\n",
    "        return loss_all\n",
    "\n",
    "\n",
    "##Write results to csv file\n",
    "def write_results(output, filename):\n",
    "    shape = output.shape\n",
    "    with open(filename, \"w\") as f:\n",
    "        csvwriter = csv.writer(f)\n",
    "        for i in range(0, len(output)):\n",
    "            if i == 0:\n",
    "                csvwriter.writerow(\n",
    "                    [\"ids\"]\n",
    "                    + [\"target\"] * int((shape[1] - 1) / 2)\n",
    "                    + [\"prediction\"] * int((shape[1] - 1) / 2)\n",
    "                )\n",
    "            elif i > 0:\n",
    "                csvwriter.writerow(output[i - 1, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "92f18656",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model trainer\n",
    "def trainer(\n",
    "    rank,\n",
    "    world_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    loss,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    train_sampler,\n",
    "    epochs,\n",
    "    verbosity,\n",
    "    filename = \"my_model_temp.pth\",\n",
    "):\n",
    "\n",
    "    train_error = val_error = test_error = epoch_time = float(\"NaN\")\n",
    "    train_start = time.time()\n",
    "    best_val_error = 1e10\n",
    "    model_best = model\n",
    "    ##Start training over epochs loop\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        lr = scheduler.optimizer.param_groups[0][\"lr\"]\n",
    "        if rank not in (\"cpu\", \"cuda\"):\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        ##Train model\n",
    "        train_error = train(model, optimizer, train_loader, loss, rank=rank)\n",
    "        if rank not in (\"cpu\", \"cuda\"):\n",
    "            torch.distributed.reduce(train_error, dst=0)\n",
    "            train_error = train_error / world_size\n",
    "\n",
    "        ##Get validation performance\n",
    "        if rank not in (\"cpu\", \"cuda\"):\n",
    "            dist.barrier()\n",
    "        if val_loader != None and rank in (0, \"cpu\", \"cuda\"):\n",
    "            if rank not in (\"cpu\", \"cuda\"):\n",
    "                val_error = evaluate(\n",
    "                    val_loader, model.module, loss, rank=rank, out=False\n",
    "                )\n",
    "            else:\n",
    "                val_error = evaluate(val_loader, model, loss, rank=rank, out=False)\n",
    "\n",
    "        ##Train loop timings\n",
    "        epoch_time = time.time() - train_start\n",
    "        train_start = time.time()\n",
    "\n",
    "        ##remember the best val error and save model and checkpoint        \n",
    "        if val_loader != None and rank in (0, \"cpu\", \"cuda\"):\n",
    "            if val_error == float(\"NaN\") or val_error < best_val_error:\n",
    "                if rank not in (\"cpu\", \"cuda\"):\n",
    "                    model_best = copy.deepcopy(model.module)\n",
    "                    torch.save(\n",
    "                        {\n",
    "                            \"state_dict\": model.state_dict(),\n",
    "                            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                            \"full_model\": model,\n",
    "                        },\n",
    "                        filename,\n",
    "                    )\n",
    "                else:\n",
    "                    model_best = copy.deepcopy(model)\n",
    "                    torch.save(\n",
    "                        {\n",
    "                            \"state_dict\": model.state_dict(),\n",
    "                            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                            \"full_model\": model,\n",
    "                        },\n",
    "                        filename,\n",
    "                    )\n",
    "            best_val_error = min(val_error, best_val_error)\n",
    "        elif val_loader == None and rank in (0, \"cpu\", \"cuda\"):\n",
    "            if rank not in (\"cpu\", \"cuda\"):\n",
    "                model_best = copy.deepcopy(model.module)\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                        \"full_model\": model,\n",
    "                    },\n",
    "                    filename,\n",
    "                )\n",
    "            else:\n",
    "                model_best = copy.deepcopy(model)\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                        \"full_model\": model,\n",
    "                    },\n",
    "                    filename,\n",
    "                )\n",
    "\n",
    "        ##scheduler on train error\n",
    "        scheduler.step(train_error)\n",
    "\n",
    "        ##Print performance\n",
    "        if epoch % verbosity == 0:\n",
    "            if rank in (0, \"cpu\", \"cuda\"):\n",
    "                print(\n",
    "                    \"Epoch: {:04d}, Learning Rate: {:.6f}, Training Error: {:.5f}, Val Error: {:.5f}, Time per epoch (s): {:.5f}\".format(\n",
    "                        epoch, lr, train_error, val_error, epoch_time\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        dist.barrier()\n",
    "\n",
    "    return model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1afe0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddp_setup(rank, world_size):\n",
    "    if rank in (\"cpu\", \"cuda\"):\n",
    "        return\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
    "    if platform.system() == 'Windows':\n",
    "        dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)    \n",
    "    else:\n",
    "        dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aefc03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup(\n",
    "    rank,\n",
    "    model_name,\n",
    "    model_params,\n",
    "    dataset,\n",
    "    load_model=False,\n",
    "    model_path=None,\n",
    "    print_model=True,\n",
    "):\n",
    "    model = DEEP_GATGNN(\n",
    "        data=dataset, **(model_params if model_params is not None else {})\n",
    "    ).to(rank)\n",
    "    if load_model == \"True\":\n",
    "        assert os.path.exists(model_path), \"Saved model not found\"\n",
    "        if str(rank) in (\"cpu\"):\n",
    "            saved = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "        else:\n",
    "            saved = torch.load(model_path)\n",
    "        model.load_state_dict(saved[\"model_state_dict\"])\n",
    "        # optimizer.load_state_dict(saved['optimizer_state_dict'])\n",
    "\n",
    "    # DDP\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        model = DistributedDataParallel(\n",
    "            model, device_ids=[rank], find_unused_parameters=True\n",
    "        )\n",
    "        # model = DistributedDataParallel(model, device_ids=[rank], find_unused_parameters=False)\n",
    "    if print_model == True and rank in (0, \"cpu\", \"cuda\"):\n",
    "        model_summary(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3ed3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_setup(\n",
    "    train_ratio,\n",
    "    val_ratio,\n",
    "    test_ratio,\n",
    "    batch_size,\n",
    "    dataset,\n",
    "    rank,\n",
    "    seed,\n",
    "    world_size=0,\n",
    "    num_workers=0,\n",
    "):\n",
    "    ##Split datasets\n",
    "    train_dataset, val_dataset, test_dataset = process.split_data(\n",
    "        dataset, train_ratio, val_ratio, test_ratio, seed\n",
    "    )\n",
    "\n",
    "    ##DDP\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        train_sampler = DistributedSampler(\n",
    "            train_dataset, num_replicas=world_size, rank=rank\n",
    "        )\n",
    "    elif rank in (\"cpu\", \"cuda\"):\n",
    "        train_sampler = None\n",
    "\n",
    "    ##Load data\n",
    "    train_loader = val_loader = test_loader = None\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "    )\n",
    "    # may scale down batch size if memory is an issue\n",
    "    if rank in (0, \"cpu\", \"cuda\"):\n",
    "        if len(val_dataset) > 0:\n",
    "            val_loader = DataLoader(\n",
    "                val_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=True,\n",
    "            )\n",
    "        if len(test_dataset) > 0:\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=True,\n",
    "            )\n",
    "    return (\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        train_sampler,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        test_dataset,\n",
    "    )\n",
    "\n",
    "def loader_setup_CV(index, batch_size, dataset, rank, world_size=0, num_workers=0):\n",
    "    ##Split datasets\n",
    "    train_dataset = [x for i, x in enumerate(dataset) if i != index]\n",
    "    train_dataset = torch.utils.data.ConcatDataset(train_dataset)\n",
    "    test_dataset = dataset[index]\n",
    "\n",
    "    ##DDP\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        train_sampler = DistributedSampler(\n",
    "            train_dataset, num_replicas=world_size, rank=rank\n",
    "        )\n",
    "    elif rank in (\"cpu\", \"cuda\"):\n",
    "        train_sampler = None\n",
    "\n",
    "    train_loader = val_loader = test_loader = None\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "    )\n",
    "    if rank in (0, \"cpu\", \"cuda\"):\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    return train_loader, test_loader, train_sampler, train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b40b0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regular(\n",
    "    rank,\n",
    "    world_size,\n",
    "    data_path,\n",
    "    job_parameters=None,\n",
    "    training_parameters=None,\n",
    "    model_parameters=None,\n",
    "):\n",
    "    ##DDP\n",
    "    ddp_setup(rank, world_size)\n",
    "    ##some issues with DDP learning rate\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        model_parameters[\"lr\"] = model_parameters[\"lr\"] * world_size\n",
    "\n",
    "    ##Get dataset\n",
    "    dataset = process.get_dataset(data_path, training_parameters[\"target_index\"], False)\n",
    "\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        dist.barrier()\n",
    "\n",
    "    ##Set up loader\n",
    "    (\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        train_sampler,\n",
    "        train_dataset,\n",
    "        _,\n",
    "        _,\n",
    "    ) = loader_setup(\n",
    "        training_parameters[\"train_ratio\"],\n",
    "        training_parameters[\"val_ratio\"],\n",
    "        training_parameters[\"test_ratio\"],\n",
    "        model_parameters[\"batch_size\"],\n",
    "        dataset,\n",
    "        rank,\n",
    "        job_parameters[\"seed\"],\n",
    "        world_size,\n",
    "    )\n",
    "\n",
    "    ##Set up model\n",
    "    model = model_setup(\n",
    "        rank,\n",
    "        model_parameters[\"model\"],\n",
    "        model_parameters,\n",
    "        dataset,\n",
    "        job_parameters[\"load_model\"],\n",
    "        job_parameters[\"model_path\"],\n",
    "        model_parameters.get(\"print_model\", True),\n",
    "    )\n",
    "\n",
    "    ##Set-up optimizer & scheduler\n",
    "    optimizer = getattr(torch.optim, model_parameters[\"optimizer\"])(\n",
    "        model.parameters(),\n",
    "        lr=model_parameters[\"lr\"],\n",
    "        **model_parameters[\"optimizer_args\"]\n",
    "    )\n",
    "    scheduler = getattr(torch.optim.lr_scheduler, model_parameters[\"scheduler\"])(\n",
    "        optimizer, **model_parameters[\"scheduler_args\"]\n",
    "    )\n",
    "\n",
    "    ##Start training\n",
    "    model = trainer(\n",
    "        rank,\n",
    "        world_size,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        training_parameters[\"loss\"],\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        train_sampler,\n",
    "        model_parameters[\"epochs\"],\n",
    "        training_parameters[\"verbosity\"],\n",
    "        \"my_model_temp.pth\",\n",
    "    )\n",
    "\n",
    "    if rank in (0, \"cpu\", \"cuda\"):\n",
    "\n",
    "        train_error = val_error = test_error = float(\"NaN\")\n",
    "\n",
    "        ##workaround to get training output in DDP mode\n",
    "        ##outputs are slightly different, could be due to dropout or batchnorm?\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=model_parameters[\"batch_size\"],\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        ##Get train error in eval mode\n",
    "        train_error, train_out = evaluate(\n",
    "            train_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    "        )\n",
    "        print(\"Train Error: {:.5f}\".format(train_error))\n",
    "\n",
    "        ##Get val error\n",
    "        if val_loader != None:\n",
    "            val_error, val_out = evaluate(\n",
    "                val_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    "            )\n",
    "            print(\"Val Error: {:.5f}\".format(val_error))\n",
    "\n",
    "        ##Get test error\n",
    "        if test_loader != None:\n",
    "            test_error, test_out = evaluate(\n",
    "                test_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    "            )\n",
    "            print(\"Test Error: {:.5f}\".format(test_error))\n",
    "\n",
    "        ##Save model\n",
    "        if job_parameters[\"save_model\"] == \"True\":\n",
    "\n",
    "            if rank not in (\"cpu\", \"cuda\"):\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                        \"full_model\": model,\n",
    "                    },\n",
    "                    job_parameters[\"model_path\"],\n",
    "                )\n",
    "            else:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                        \"full_model\": model,\n",
    "                    },\n",
    "                    job_parameters[\"model_path\"],\n",
    "                )\n",
    "\n",
    "        ##Write outputs\n",
    "        if job_parameters[\"write_output\"] == \"True\":\n",
    "\n",
    "            write_results(\n",
    "                train_out, str(job_parameters[\"job_name\"]) + \"_train_outputs.csv\"\n",
    "            )\n",
    "            if val_loader != None:\n",
    "                write_results(\n",
    "                    val_out, str(job_parameters[\"job_name\"]) + \"_val_outputs.csv\"\n",
    "                )\n",
    "            if test_loader != None:\n",
    "                write_results(\n",
    "                    test_out, str(job_parameters[\"job_name\"]) + \"_test_outputs.csv\"\n",
    "                )\n",
    "\n",
    "        if rank not in (\"cpu\", \"cuda\"):\n",
    "            dist.destroy_process_group()\n",
    "\n",
    "        ##Write out model performance to file\n",
    "        error_values = np.array((train_error.cpu(), val_error.cpu(), test_error.cpu()))\n",
    "        if job_parameters.get(\"write_error\") == \"True\":\n",
    "            np.savetxt(\n",
    "                job_parameters[\"job_name\"] + \"_errorvalues.csv\",\n",
    "                error_values[np.newaxis, ...],\n",
    "                delimiter=\",\",\n",
    "            )\n",
    "\n",
    "        return error_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f0c2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Predict using a saved movel\n",
    "def predict(dataset, loss, job_parameters=None):\n",
    "\n",
    "    rank = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ##Loads predict dataset in one go, care needed for large datasets)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    ##Load saved model\n",
    "    assert os.path.exists(job_parameters[\"model_path\"]), \"Saved model not found\"\n",
    "    if str(rank) == \"cpu\":\n",
    "        saved = torch.load(\n",
    "            job_parameters[\"model_path\"], map_location=torch.device(\"cpu\")\n",
    "        )\n",
    "    else:\n",
    "        saved = torch.load(\n",
    "            job_parameters[\"model_path\"], map_location=torch.device(\"cuda\")\n",
    "        )\n",
    "    model = saved[\"full_model\"]\n",
    "    model = model.to(rank)\n",
    "    model_summary(model)\n",
    "\n",
    "    ##Get predictions\n",
    "    time_start = time.time()\n",
    "    test_error, test_out = evaluate(loader, model, loss, rank, out=True)\n",
    "    elapsed_time = time.time() - time_start\n",
    "\n",
    "    print(\"Evaluation time (s): {:.5f}\".format(elapsed_time))\n",
    "\n",
    "    ##Write output\n",
    "    if job_parameters[\"write_output\"] == \"True\":\n",
    "        write_results(\n",
    "            test_out, str(job_parameters[\"job_name\"]) + \"_predicted_outputs.csv\"\n",
    "        )\n",
    "\n",
    "    return test_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb90d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "###n-fold cross validation\n",
    "def train_CV(\n",
    "    rank,\n",
    "    world_size,\n",
    "    data_path,\n",
    "    job_parameters=None,\n",
    "    training_parameters=None,\n",
    "    model_parameters=None,\n",
    "):\n",
    "\n",
    "   #job_parameters[\"load_model\"] = \"False\"\n",
    "    #job_parameters[\"save_model\"] = \"False\"\n",
    "    #job_parameters[\"model_path\"] = None\n",
    "    ##DDP\n",
    "    ddp_setup(rank, world_size)\n",
    "    ##some issues with DDP learning rate\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        model_parameters[\"lr\"] = model_parameters[\"lr\"] * world_size\n",
    "\n",
    "    ##Get dataset\n",
    "    cwd = os.getcwd()\n",
    "    dataset = process.get_dataset(data_path, training_parameters[\"target_index\"], False)\n",
    "\n",
    "    ##Split datasets\n",
    "    cv_dataset = process.split_data_CV(\n",
    "        dataset, num_folds=job_parameters[\"cv_folds\"], seed=job_parameters[\"seed\"]\n",
    "    )\n",
    "    cv_error = 0\n",
    "\n",
    "    for index in range(0, len(cv_dataset)):\n",
    "\n",
    "        ##Set up model\n",
    "        if index == 0:\n",
    "            model = model_setup(\n",
    "                rank,\n",
    "                model_parameters[\"model\"],\n",
    "                model_parameters,\n",
    "                dataset,\n",
    "                job_parameters[\"load_model\"],\n",
    "                job_parameters[\"model_path\"],\n",
    "                print_model=True,\n",
    "            )\n",
    "        else:\n",
    "            model = model_setup(\n",
    "                rank,\n",
    "                model_parameters[\"model\"],\n",
    "                model_parameters,\n",
    "                dataset,\n",
    "                job_parameters[\"load_model\"],\n",
    "                job_parameters[\"model_path\"],\n",
    "                print_model=False,\n",
    "            )\n",
    "\n",
    "        ##Set-up optimizer & scheduler\n",
    "        optimizer = getattr(torch.optim, model_parameters[\"optimizer\"])(\n",
    "            model.parameters(),\n",
    "            lr=model_parameters[\"lr\"],\n",
    "            **model_parameters[\"optimizer_args\"]\n",
    "        )\n",
    "        scheduler = getattr(torch.optim.lr_scheduler, model_parameters[\"scheduler\"])(\n",
    "            optimizer, **model_parameters[\"scheduler_args\"]\n",
    "        )\n",
    "\n",
    "        ##Set up loader\n",
    "        train_loader, test_loader, train_sampler, train_dataset, _ = loader_setup_CV(\n",
    "            index, model_parameters[\"batch_size\"], cv_dataset, rank, world_size\n",
    "        )\n",
    "\n",
    "        ##Start training\n",
    "        model = trainer(\n",
    "            rank,\n",
    "            world_size,\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            training_parameters[\"loss\"],\n",
    "            train_loader,\n",
    "            None,\n",
    "            train_sampler,\n",
    "            model_parameters[\"epochs\"],\n",
    "            training_parameters[\"verbosity\"],\n",
    "            \"my_model_temp.pth\",\n",
    "        )\n",
    "\n",
    "        if rank not in (\"cpu\", \"cuda\"):\n",
    "            dist.barrier()\n",
    "\n",
    "        if rank in (0, \"cpu\", \"cuda\"):\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=model_parameters[\"batch_size\"],\n",
    "                shuffle=False,\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "            )\n",
    "\n",
    "            ##Get train error\n",
    "            train_error, train_out = evaluate(\n",
    "                train_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    "            )\n",
    "            print(\"Train Error: {:.5f}\".format(train_error))\n",
    "\n",
    "            ##Get test error\n",
    "            test_error, test_out = evaluate(\n",
    "                test_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    "            )\n",
    "            print(\"Test Error: {:.5f}\".format(test_error))\n",
    "\n",
    "            cv_error = cv_error + test_error\n",
    "\n",
    "            if index == 0:\n",
    "                total_rows = test_out\n",
    "            else:\n",
    "                total_rows = np.vstack((total_rows, test_out))\n",
    "\n",
    "    ##Write output\n",
    "    if rank in (0, \"cpu\", \"cuda\"):\n",
    "        if job_parameters[\"write_output\"] == \"True\":\n",
    "            if test_loader != None:\n",
    "                write_results(\n",
    "                    total_rows, str(job_parameters[\"job_name\"]) + \"_CV_outputs.csv\"\n",
    "                )\n",
    "\n",
    "        cv_error = cv_error / len(cv_dataset)\n",
    "        print(\"CV Error: {:.5f}\".format(cv_error))\n",
    "\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "    return cv_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc829e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(\n",
    "    data_path,\n",
    "    job_parameters=None,\n",
    "    training_parameters=None,\n",
    "    model_parameters=None,\n",
    "):\n",
    "\n",
    "    world_size = torch.cuda.device_count()\n",
    "    job_name = job_parameters[\"job_name\"]\n",
    "    write_output = job_parameters[\"write_output\"]\n",
    "    model_path = job_parameters[\"model_path\"]\n",
    "    job_parameters[\"write_error\"] = \"True\"\n",
    "    job_parameters[\"write_output\"] = \"True\"\n",
    "    job_parameters[\"load_model\"] = \"False\"\n",
    "    ##Loop over number of repeated trials\n",
    "    for i in range(0, len(job_parameters[\"ensemble_list\"])):\n",
    "        job_parameters[\"job_name\"] = job_name + str(i)\n",
    "        job_parameters[\"model_path\"] = (\n",
    "            str(i) + \"_\" + job_parameters[\"ensemble_list\"][i] + \"_\" + model_path\n",
    "        )\n",
    "\n",
    "        if world_size == 0:\n",
    "            print(\"Running on CPU - this will be slow\")\n",
    "            training.train_regular(\n",
    "                \"cpu\",\n",
    "                world_size,\n",
    "                data_path,\n",
    "                job_parameters,\n",
    "                training_parameters,\n",
    "                model_parameters[job_parameters[\"ensemble_list\"][i]],\n",
    "            )\n",
    "        elif world_size > 0:\n",
    "            if job_parameters[\"parallel\"] == \"True\":\n",
    "                print(\"Running on\", world_size, \"GPUs\")\n",
    "                mp.spawn(\n",
    "                    training.train_regular,\n",
    "                    args=(\n",
    "                        world_size,\n",
    "                        data_path,\n",
    "                        job_parameters,\n",
    "                        training_parameters,\n",
    "                        model_parameters[job_parameters[\"ensemble_list\"][i]],\n",
    "                    ),\n",
    "                    nprocs=world_size,\n",
    "                    join=True,\n",
    "                )\n",
    "            if job_parameters[\"parallel\"] == \"False\":\n",
    "                print(\"Running on one GPU\")\n",
    "                training.train_regular(\n",
    "                    \"cuda\",\n",
    "                    world_size,\n",
    "                    data_path,\n",
    "                    job_parameters,\n",
    "                    training_parameters,\n",
    "                    model_parameters[job_parameters[\"ensemble_list\"][i]],\n",
    "                )\n",
    "\n",
    "    ##Compile error metrics from individual models\n",
    "    print(\"Individual training finished.\")\n",
    "    print(\"Compiling metrics from individual models...\")\n",
    "    error_values = np.zeros((len(job_parameters[\"ensemble_list\"]), 3))\n",
    "    for i in range(0, len(job_parameters[\"ensemble_list\"])):\n",
    "        filename = job_name + str(i) + \"_errorvalues.csv\"\n",
    "        error_values[i] = np.genfromtxt(filename, delimiter=\",\")\n",
    "    mean_values = [\n",
    "        np.mean(error_values[:, 0]),\n",
    "        np.mean(error_values[:, 1]),\n",
    "        np.mean(error_values[:, 2]),\n",
    "    ]\n",
    "    std_values = [\n",
    "        np.std(error_values[:, 0]),\n",
    "        np.std(error_values[:, 1]),\n",
    "        np.std(error_values[:, 2]),\n",
    "    ]\n",
    "\n",
    "    # average ensembling, takes the mean of the predictions\n",
    "    for i in range(0, len(job_parameters[\"ensemble_list\"])):\n",
    "        filename = job_name + str(i) + \"_test_outputs.csv\"\n",
    "        test_out = np.genfromtxt(filename, delimiter=\",\", skip_header=1)\n",
    "        if i == 0:\n",
    "            test_total = test_out\n",
    "        elif i > 0:\n",
    "            test_total = np.column_stack((test_total, test_out[:, 2]))\n",
    "\n",
    "    ensemble_test = np.mean(np.array(test_total[:, 2:]).astype(np.float), axis=1)\n",
    "    ensemble_test_error = getattr(F, training_parameters[\"loss\"])(\n",
    "        torch.tensor(ensemble_test),\n",
    "        torch.tensor(test_total[:, 1].astype(np.float)),\n",
    "    )\n",
    "    test_total = np.column_stack((test_total, ensemble_test))\n",
    "    \n",
    "    ##Print performance\n",
    "    for i in range(0, len(job_parameters[\"ensemble_list\"])):\n",
    "        print(\n",
    "            job_parameters[\"ensemble_list\"][i]\n",
    "            + \" Test Error: {:.5f}\".format(error_values[i, 2])\n",
    "        )\n",
    "    print(\n",
    "        \"Test Error Avg: {:.3f}, Test Standard Dev: {:.3f}\".format(\n",
    "            mean_values[2], std_values[2]\n",
    "        )\n",
    "    )\n",
    "    print(\"Ensemble Error: {:.5f}\".format(ensemble_test_error))\n",
    "    \n",
    "    ##Write output\n",
    "    if write_output == \"True\" or write_output == \"Partial\":\n",
    "        with open(\n",
    "            str(job_name) + \"_test_ensemble_outputs.csv\", \"w\"\n",
    "        ) as f:\n",
    "            csvwriter = csv.writer(f)\n",
    "            for i in range(0, len(test_total) + 1):\n",
    "                if i == 0:\n",
    "                    csvwriter.writerow(\n",
    "                        [\n",
    "                            \"ids\",\n",
    "                            \"target\",\n",
    "                        ]\n",
    "                        + job_parameters[\"ensemble_list\"]\n",
    "                        + [\"ensemble\"]\n",
    "                    )\n",
    "                elif i > 0:\n",
    "                    csvwriter.writerow(test_total[i - 1, :])\n",
    "    if write_output == \"False\" or write_output == \"Partial\":\n",
    "        for i in range(0, len(job_parameters[\"ensemble_list\"])):\n",
    "            filename = job_name + str(i) + \"_errorvalues.csv\"\n",
    "            os.remove(filename)\n",
    "            filename = job_name + str(i) + \"_test_outputs.csv\"\n",
    "            os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c8f48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(\n",
    "    dataset,\n",
    "    model_path,\n",
    "    tsne_args,\n",
    "):\n",
    "\n",
    "    # imports\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.manifold import TSNE\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    rank = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inputs = []\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        inputs.append(input)\n",
    "\n",
    "    assert os.path.exists(model_path), \"saved model not found\"\n",
    "    if str(rank) == \"cpu\":\n",
    "        saved = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "    else:\n",
    "        saved = torch.load(model_path, map_location=torch.device(\"cuda\"))\n",
    "    model = saved[\"full_model\"]\n",
    "    model_summary(model)\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=512,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    ##Grabs the input of the first linear layer after the GNN\n",
    "    model.post_lin_list[0].register_forward_hook(hook)\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            data = data.to(rank)\n",
    "            output = model(data)\n",
    "\n",
    "    inputs = [i for sub in inputs for i in sub]\n",
    "    inputs = torch.cat(inputs)\n",
    "    inputs = inputs.cpu().numpy()\n",
    "    print(\"Number of samples: \", inputs.shape[0])\n",
    "    print(\"Number of features: \", inputs.shape[1])\n",
    "\n",
    "    # only works for when targets has one index\n",
    "    targets = dataset.data.y.numpy()\n",
    "\n",
    "    # pca = PCA(n_components=2)\n",
    "    # pca_out=pca.fit_transform(inputs)\n",
    "    # print(pca_out.shape)\n",
    "    # np.savetxt('pca.csv', pca_out, delimiter=',')\n",
    "    # plt.scatter(pca_out[:,1],pca_out[:,0],c=targets,s=15)\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "    # plt.clf()\n",
    "\n",
    "    ##Start t-SNE analysis\n",
    "    tsne = TSNE(**tsne_args)\n",
    "    tsne_out = tsne.fit_transform(inputs)\n",
    "    rows = zip(\n",
    "        dataset.data.structure_id,\n",
    "        list(dataset.data.y.numpy()),\n",
    "        list(tsne_out[:, 0]),\n",
    "        list(tsne_out[:, 1]),\n",
    "    )\n",
    "\n",
    "    with open(\"tsne_output.csv\", \"w\") as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=\",\")\n",
    "        for row in rows:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    main = plt.scatter(tsne_out[:, 1], tsne_out[:, 0], c=targets, s=3)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    cbar = plt.colorbar(main, ax=ax)\n",
    "    stdev = np.std(targets)\n",
    "    cbar.mappable.set_clim(\n",
    "        np.mean(targets) - 2 * np.std(targets), np.mean(targets) + 2 * np.std(targets)\n",
    "    )\n",
    "    # cbar.ax.tick_params(labelsize=50)\n",
    "    # cbar.ax.tick_params(size=40)\n",
    "    plt.savefig(\"tsne_output.png\", format=\"png\", dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1480f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import ase\n",
    "import glob\n",
    "from ase import io\n",
    "from scipy.stats import rankdata\n",
    "from scipy import interpolate\n",
    "\n",
    "##torch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader, Dataset, Data, InMemoryDataset\n",
    "from torch_geometric.utils import dense_to_sparse, degree, add_self_loops\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "################################################################################\n",
    "# Data splitting\n",
    "################################################################################\n",
    "\n",
    "##basic train, val, test split\n",
    "def split_data(\n",
    "    dataset,\n",
    "    train_ratio,\n",
    "    val_ratio,\n",
    "    test_ratio,\n",
    "    seed=np.random.randint(1, 1e6),\n",
    "    save=False,\n",
    "):\n",
    "    dataset_size = len(dataset)\n",
    "    if (train_ratio + val_ratio + test_ratio) <= 1:\n",
    "        train_length = int(dataset_size * train_ratio)\n",
    "        val_length = int(dataset_size * val_ratio)\n",
    "        test_length = int(dataset_size * test_ratio)\n",
    "        unused_length = dataset_size - train_length - val_length - test_length\n",
    "        (\n",
    "            train_dataset,\n",
    "            val_dataset,\n",
    "            test_dataset,\n",
    "            unused_dataset,\n",
    "        ) = torch.utils.data.random_split(\n",
    "            dataset,\n",
    "            [train_length, val_length, test_length, unused_length],\n",
    "            generator=torch.Generator().manual_seed(seed),\n",
    "        )\n",
    "        print(\n",
    "            \"train length:\",\n",
    "            train_length,\n",
    "            \"val length:\",\n",
    "            val_length,\n",
    "            \"test length:\",\n",
    "            test_length,\n",
    "            \"unused length:\",\n",
    "            unused_length,\n",
    "            \"seed :\",\n",
    "            seed,\n",
    "        )\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "    else:\n",
    "        print(\"invalid ratios\")\n",
    "\n",
    "\n",
    "##Basic CV split\n",
    "def split_data_CV(dataset, num_folds=5, seed=np.random.randint(1, 1e6), save=False):\n",
    "    dataset_size = len(dataset)\n",
    "    fold_length = int(dataset_size / num_folds)\n",
    "    unused_length = dataset_size - fold_length * num_folds\n",
    "    folds = [fold_length for i in range(num_folds)]\n",
    "    folds.append(unused_length)\n",
    "    cv_dataset = torch.utils.data.random_split(\n",
    "        dataset, folds, generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    print(\"fold length :\", fold_length, \"unused length:\", unused_length, \"seed\", seed)\n",
    "    return cv_dataset[0:num_folds]\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Pytorch datasets\n",
    "################################################################################\n",
    "\n",
    "##Fetch dataset; processes the raw data if specified\n",
    "def get_dataset(data_path, target_index, reprocess=\"False\", processing_args=None):\n",
    "    if processing_args == None:\n",
    "        processed_path = \"processed\"\n",
    "    else:\n",
    "        processed_path = processing_args.get(\"processed_path\", \"processed\")\n",
    "\n",
    "    transforms = GetY(index=target_index)\n",
    "\n",
    "    if os.path.exists(data_path) == False:\n",
    "        print(\"Data not found in:\", data_path)\n",
    "        sys.exit()\n",
    "\n",
    "    if reprocess == \"True\":\n",
    "        os.system(\"rm -rf \" + os.path.join(data_path, processed_path))\n",
    "        process_data(data_path, processed_path, processing_args)\n",
    "\n",
    "    if os.path.exists(os.path.join(data_path, processed_path, \"ehc.pt\")) == True:\n",
    "        dataset = StructureDataset(\n",
    "            data_path,\n",
    "            processed_path,\n",
    "            transforms,\n",
    "        )\n",
    "    elif os.path.exists(os.path.join(data_path, processed_path, \"data0.pt\")) == True:\n",
    "        dataset = StructureDataset_large(\n",
    "            data_path,\n",
    "            processed_path,\n",
    "            transforms,\n",
    "        )\n",
    "    else:\n",
    "        process_data(data_path, processed_path, processing_args)\n",
    "        if os.path.exists(os.path.join(data_path, processed_path, \"ehc.pt\")) == True:\n",
    "            dataset = StructureDataset(\n",
    "                data_path,\n",
    "                processed_path,\n",
    "                transforms,\n",
    "            )\n",
    "        elif os.path.exists(os.path.join(data_path, processed_path, \"data0.pt\")) == True:\n",
    "            dataset = StructureDataset_large(\n",
    "                data_path,\n",
    "                processed_path,\n",
    "                transforms,\n",
    "            )        \n",
    "    return dataset\n",
    "\n",
    "\n",
    "##Dataset class from pytorch/pytorch geometric; inmemory case\n",
    "class StructureDataset(InMemoryDataset):\n",
    "    def __init__(\n",
    "        self, data_path, processed_path=\"processed\", transform=None, pre_transform=None\n",
    "    ):\n",
    "        self.data_path = data_path\n",
    "        self.processed_path = processed_path\n",
    "        super(StructureDataset, self).__init__(data_path, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return os.path.join(self.data_path, self.processed_path)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        file_names = [\"ehc.pt\"]\n",
    "        return file_names\n",
    "\n",
    "\n",
    "\n",
    "        return data\n",
    "##Get specified y index from data.y\n",
    "class GetY(object):\n",
    "    def __init__(self, index=0):\n",
    "        self.index = index\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # Specify target.\n",
    "        if self.index != -1:\n",
    "            data.y = data.y[0][self.index]\n",
    "        return data\n",
    "def model_summary(model):\n",
    "    model_params_list = list(model.named_parameters())\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    line_new = \"{:>30}  {:>20} {:>20}\".format(\n",
    "        \"Layer.Parameter\", \"Param Tensor Shape\", \"Param #\"\n",
    "    )\n",
    "    print(line_new)\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    for elem in model_params_list:\n",
    "        p_name = elem[0]\n",
    "        p_shape = list(elem[1].size())\n",
    "        p_count = torch.tensor(elem[1].size()).prod().item()\n",
    "        line_new = \"{:>30}  {:>20} {:>20}\".format(p_name, str(p_shape), str(p_count))\n",
    "        print(line_new)\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    total_params = sum([param.nelement() for param in model.parameters()])\n",
    "    print(\"Total params:\", total_params)\n",
    "    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params:\", num_trainable_params)\n",
    "    print(\"Non-trainable params:\", total_params - num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d1c0927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\moham\\\\Downloads\\\\sams'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f24e9616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length: 41304 val length: 2429 test length: 4859 unused length: 2 seed : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "database= get_dataset(cwd,0)\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    train_sampler,\n",
    "    train_dataset,\n",
    "    _,\n",
    "    _,\n",
    ") = loader_setup(\n",
    "    0.85,\n",
    "    0.05,\n",
    "    0.10,\n",
    "    90,\n",
    "    database,\n",
    "    'cuda',\n",
    "    7,\n",
    "    0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "899cafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, Dropout, Parameter\n",
    "from torch_geometric.nn.conv  import MessagePassing\n",
    "from torch_geometric.utils    import softmax as tg_softmax\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (\n",
    "    Set2Set,\n",
    "    global_mean_pool,\n",
    "    global_add_pool,\n",
    "    global_max_pool,\n",
    "    GCNConv,\n",
    "    DiffGroupNorm\n",
    ")\n",
    "from torch_scatter import scatter_mean, scatter_add, scatter_max, scatter\n",
    "\n",
    "# CGCNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# %%\n",
    "RNG_SEED = 42\n",
    "torch.manual_seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "data_type_torch = torch.float32\n",
    "\n",
    "\n",
    "# %%\n",
    "class ResidualNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Feed forward Residual Neural Network as seen in Roost.\n",
    "    https://doi.org/10.1038/s41467-020-19964-7\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_layer_dims):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "        ----------\n",
    "        input_dim: int\n",
    "        output_dim: int\n",
    "        hidden_layer_dims: list(int)\n",
    "        \"\"\"\n",
    "        super(ResidualNetwork, self).__init__()\n",
    "        dims = [input_dim]+hidden_layer_dims\n",
    "        self.fcs = nn.ModuleList([nn.Linear(dims[i], dims[i+1])\n",
    "                                  for i in range(len(dims)-1)])\n",
    "        self.res_fcs = nn.ModuleList([nn.Linear(dims[i], dims[i+1], bias=False)\n",
    "                                      if (dims[i] != dims[i+1])\n",
    "                                      else nn.Identity()\n",
    "                                      for i in range(len(dims)-1)])\n",
    "        self.acts = nn.ModuleList([nn.LeakyReLU() for _ in range(len(dims)-1)])\n",
    "        self.fc_out = nn.Linear(dims[-1], output_dim)\n",
    "\n",
    "    def forward(self, fea):\n",
    "        for fc, res_fc, act in zip(self.fcs, self.res_fcs, self.acts):\n",
    "            fea = act(fc(fea))+res_fc(fea)\n",
    "        return self.fc_out(fea)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "\n",
    "# %%\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 compute_device=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.compute_device = compute_device\n",
    "\n",
    "       # elem_dir = 'data/element_properties'\n",
    "        # # Choose what element information the model receives\n",
    "        mat2vec = 'mat2vec.csv'  # element embedding\n",
    "        # mat2vec = f'{elem_dir}/onehot.csv'  # onehot encoding (atomic number)\n",
    "        # mat2vec = f'{elem_dir}/random_200.csv'  # random vec for elements\n",
    "\n",
    "        cbfv = pd.read_csv(mat2vec, index_col=0).values\n",
    "        feat_size = cbfv.shape[-1]\n",
    "        self.fc_mat2vec = nn.Linear(feat_size, d_model).to(self.compute_device)\n",
    "        zeros = np.zeros((1, feat_size))\n",
    "        cat_array = np.concatenate([zeros, cbfv])\n",
    "        cat_array = torch.as_tensor(cat_array, dtype=data_type_torch)\n",
    "        self.cbfv = nn.Embedding.from_pretrained(cat_array) \\\n",
    "            .to(self.compute_device, dtype=data_type_torch)\n",
    "\n",
    "    def forward(self, src):\n",
    "        mat2vec_emb = self.cbfv(src)\n",
    "        x_emb = self.fc_mat2vec(mat2vec_emb)\n",
    "        return x_emb\n",
    "\n",
    "\n",
    "# %%\n",
    "class FractionalEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoding element fractional amount using a \"fractional encoding\" inspired\n",
    "    by the positional encoder discussed by Vaswani.\n",
    "    https://arxiv.org/abs/1706.03762\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 resolution=100,\n",
    "                 log10=False,\n",
    "                 compute_device=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model//2\n",
    "        self.resolution = resolution\n",
    "        self.log10 = log10\n",
    "        self.compute_device = compute_device\n",
    "\n",
    "        x = torch.linspace(0, self.resolution - 1,\n",
    "                           self.resolution,\n",
    "                           requires_grad=False) \\\n",
    "            .view(self.resolution, 1)\n",
    "        fraction = torch.linspace(0, self.d_model - 1,\n",
    "                                  self.d_model,\n",
    "                                  requires_grad=False) \\\n",
    "            .view(1, self.d_model).repeat(self.resolution, 1)\n",
    "\n",
    "        pe = torch.zeros(self.resolution, self.d_model)\n",
    "        pe[:, 0::2] = torch.sin(x /torch.pow(\n",
    "            50,2 * fraction[:, 0::2] / self.d_model))\n",
    "        pe[:, 1::2] = torch.cos(x / torch.pow(\n",
    "            50, 2 * fraction[:, 1::2] / self.d_model))\n",
    "        pe = self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.clone()\n",
    "        if self.log10:\n",
    "            x = 0.0025 * (torch.log2(x))**2\n",
    "            # clamp x[x > 1] = 1\n",
    "            x = torch.clamp(x, max=1)\n",
    "            # x = 1 - x  # for sinusoidal encoding at x=0\n",
    "        # clamp x[x < 1/self.resolution] = 1/self.resolution\n",
    "        x = torch.clamp(x, min=1/self.resolution)\n",
    "        frac_idx = torch.round(x * (self.resolution)).to(dtype=torch.long) - 1\n",
    "        out = self.pe[frac_idx]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# %%\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 N,\n",
    "                 heads,\n",
    "                 frac=False,\n",
    "                 attn=True,\n",
    "                 compute_device=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.N = N\n",
    "        self.heads = heads\n",
    "        self.fractional = frac\n",
    "        self.attention = attn\n",
    "        self.compute_device = compute_device\n",
    "        self.embed = Embedder(d_model=self.d_model,\n",
    "                              compute_device=self.compute_device)\n",
    "        self.pe = FractionalEncoder(self.d_model, resolution=5000, log10=False)\n",
    "        self.ple = FractionalEncoder(self.d_model, resolution=5000, log10=True)\n",
    "\n",
    "        self.emb_scaler = nn.parameter.Parameter(torch.tensor([1.]))\n",
    "        self.pos_scaler = nn.parameter.Parameter(torch.tensor([1.]))\n",
    "        self.pos_scaler_log = nn.parameter.Parameter(torch.tensor([1.]))\n",
    "\n",
    "        if self.attention:\n",
    "            encoder_layer = nn.TransformerEncoderLayer(self.d_model,\n",
    "                                                       nhead=self.heads,\n",
    "                                                       dim_feedforward=2048,\n",
    "                                                       dropout=0.1)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layer,\n",
    "                                                             num_layers=self.N)\n",
    "\n",
    "    def forward(self, src, frac):\n",
    "        x = self.embed(src) * 2**self.emb_scaler\n",
    "        mask = frac.unsqueeze(dim=-1)\n",
    "        mask = torch.matmul(mask, mask.transpose(-2, -1))\n",
    "        mask[mask != 0] = 1\n",
    "        src_mask = mask[:, 0] != 1\n",
    "\n",
    "        pe = torch.zeros_like(x)\n",
    "        ple = torch.zeros_like(x)\n",
    "        pe_scaler = 2**(1-self.pos_scaler)**2\n",
    "        ple_scaler = 2**(1-self.pos_scaler_log)**2\n",
    "        pe[:, :, :self.d_model//2] = self.pe(frac) * pe_scaler\n",
    "        ple[:, :, self.d_model//2:] = self.ple(frac) * ple_scaler\n",
    "\n",
    "        if self.attention:\n",
    "            x_src = x + pe + ple\n",
    "            x_src = x_src.transpose(0, 1)\n",
    "            x = self.transformer_encoder(x_src,\n",
    "                                         src_key_padding_mask=src_mask)\n",
    "            x = x.transpose(0, 1)\n",
    "\n",
    "        if self.fractional:\n",
    "            x = x * frac.unsqueeze(2).repeat(1, 1, self.d_model)\n",
    "\n",
    "        hmask = mask[:, :, 0:1].repeat(1, 1, self.d_model)\n",
    "        if mask is not None:\n",
    "            x = x.masked_fill(hmask == 0, 0)\n",
    "\n",
    "        return x\n",
    "class DEEP_GATGNN(torch.nn.Module):\n",
    "    def __init__(self, data,\n",
    "        out_dims=64,\n",
    "        d_model=512,\n",
    "        N=3,\n",
    "        heads=4,\n",
    "        compute_device=None,\n",
    "        residual_nn='roost',\n",
    "        dim1=64,\n",
    "        dim2=150,\n",
    "        pre_fc_count=1,\n",
    "        gc_count=5,\n",
    "        post_fc_count=1,\n",
    "        pool=\"global_add_pool\",\n",
    "        pool_order=\"early\",\n",
    "        batch_norm=\"True\",\n",
    "        batch_track_stats=\"True\",\n",
    "        act=\"softplus\",\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(DEEP_GATGNN, self).__init__()\n",
    "        output_dim = len(data[0].y[0])\n",
    "        if post_fc_count > 0:\n",
    "            self.lin_out = torch.nn.Linear(dim2, output_dim)\n",
    "\n",
    "        \n",
    "        if batch_track_stats == \"False\":\n",
    "            self.batch_track_stats = False \n",
    "        else:\n",
    "            self.batch_track_stats = True \n",
    "\n",
    "        self.batch_norm   = batch_norm\n",
    "        self.pool         = pool\n",
    "        self.act          = act\n",
    "        self.pool_order   = pool_order\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.avg = False\n",
    "        self.out_dims = out_dims\n",
    "        self.d_model = d_model\n",
    "        self.N = N\n",
    "        self.heads = heads\n",
    "        self.compute_device = compute_device\n",
    "        \n",
    "\n",
    "        self.encoder = Encoder(d_model=self.d_model,\n",
    "                               N=self.N,\n",
    "                               heads=self.heads,\n",
    "                               compute_device=self.compute_device)\n",
    "        if residual_nn == 'roost':\n",
    "            # use the Roost residual network\n",
    "            self.out_hidden = [1024, 512, 256, 128]\n",
    "            self.output_nn = ResidualNetwork(self.d_model,\n",
    "                                             self.out_dims,\n",
    "                                             self.out_hidden)\n",
    "        else:\n",
    "            # use a simpler residual network\n",
    "            self.out_hidden = [256, 128]\n",
    "            self.output_nn = ResidualNetwork(self.d_model,\n",
    "                                             self.out_dims,\n",
    "                                             self.out_hidden)\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "\n",
    "        output = self.encoder(data.src.to(dtype=torch.long,non_blocking=True), data.frac.to(dtype=torch.float,non_blocking=True))\n",
    "        mask = (data.src == 0).unsqueeze(-1).repeat(1, 1, self.out_dims)\n",
    "        output = self.output_nn(output)\n",
    "        #if self.avg:\n",
    "        output = output.masked_fill(mask, 0)\n",
    "        output = output.sum(dim=1)/(~mask).sum(dim=1)\n",
    "       # print(output.size())\n",
    "        ##Post-GNN dense layers\n",
    "       # print(output.size(),out_x.size())\n",
    "      #  out_x = torch.cat((out_x,output),0)\n",
    "       # print(out_x.size())\n",
    "\n",
    "         #   print(out_x.size())\n",
    "        out       = self.lin_out(output)\n",
    "\n",
    "\n",
    "        #print(out_x.size())\n",
    "        #out_x = torch.cat((out_x,output),0)\n",
    "       # print(out.size())\n",
    "                \n",
    "        #output = self.encoder(data.src, data.frac)\n",
    "\n",
    "        # average the \"element contribution\" at the end\n",
    "        # mask so you only average \"elements\"\n",
    "\n",
    "        #mask = (data.src == 0).unsqueeze(-1).repeat(1, 1, self.out_dims)\n",
    "        #output = self.output_nn(output)  # simple linear\n",
    "        #if self.avg:\n",
    "         #   output = output.masked_fill(mask, 0)\n",
    "          #  output = output.sum(dim=1)/(~mask).sum(dim=1)\n",
    "        #    output, logits = output.chunk(2, dim=-1)\n",
    "         #   probability = torch.ones_like(output)\n",
    "         #   probability[:, :logits.shape[-1]] = torch.sigmoid(logits)\n",
    "         #   output = output * probability\n",
    "        if out.shape[1] == 1:\n",
    "            return out.view(-1)\n",
    "        else:\n",
    "            #print()\n",
    "            return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffa3026e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##Set up model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_setup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDEEP_GATGNN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mmodel_setup\u001b[1;34m(rank, model_name, model_params, dataset, load_model, model_path, print_model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_setup\u001b[39m(\n\u001b[0;32m      2\u001b[0m     rank,\n\u001b[0;32m      3\u001b[0m     model_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     print_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m ):\n\u001b[1;32m---> 10\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mDEEP_GATGNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(rank)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved model not found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36mDEEP_GATGNN.__init__\u001b[1;34m(self, data, out_dims, d_model, N, heads, compute_device, residual_nn, dim1, dim2, pre_fc_count, gc_count, post_fc_count, pool, pool_order, batch_norm, batch_track_stats, act, dropout_rate, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data,\n\u001b[0;32m    213\u001b[0m     out_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m    214\u001b[0m     d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    231\u001b[0m ):\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28msuper\u001b[39m(DEEP_GATGNN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 233\u001b[0m     output_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m post_fc_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(dim2, output_dim)\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "##Set up model\n",
    "model = model_setup(\n",
    "    'cuda',\n",
    "    'DEEP_GATGNN',\n",
    "    model_parameters,\n",
    "    database\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3b547dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp_setup('cuda', 0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ##some issues with DDP learning rate\n",
    "    #if rank not in (\"cpu\", \"cuda\"):\n",
    "     #   model_parameters[\"lr\"] = model_parameters[\"lr\"] * world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d63f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = getattr(torch.optim, model_parameters[\"optimizer\"])(\n",
    "    model.parameters(),\n",
    "    lr=model_parameters[\"lr\"],\n",
    "    **model_parameters[\"optimizer_args\"]\n",
    ")\n",
    "scheduler = getattr(torch.optim.lr_scheduler, model_parameters[\"scheduler\"])(\n",
    "    optimizer, **model_parameters[\"scheduler_args\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82ff6049",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_model_temp.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(rank, world_size, model, optimizer, scheduler, loss, train_loader, val_loader, train_sampler, epochs, verbosity, filename)\u001b[0m\n\u001b[0;32m     26\u001b[0m     train_sampler\u001b[38;5;241m.\u001b[39mset_epoch(epoch)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m##Train model\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m train_error \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     30\u001b[0m     torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mreduce(train_error, dst\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loader, loss_method, rank)\u001b[0m\n\u001b[0;32m     25\u001b[0m loss_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     26\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     28\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(rank)\n\u001b[0;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataset.py:471\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\dataset.py:198\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m    197\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[1;32m--> 198\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mGetY.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Specify target.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 166\u001b[0m         data\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex]\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model = trainer(\n",
    "        'cuda',\n",
    "        0,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        training_parameters[\"loss\"],\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        train_sampler,\n",
    "        model_parameters[\"epochs\"],\n",
    "        training_parameters[\"verbosity\"],\n",
    "        \"my_model_temp.pth\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c717b2b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39my[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "517c86ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: 0.01754\n",
      "Val Error: 0.07622\n",
      "Test Error: 0.07483\n"
     ]
    }
   ],
   "source": [
    "#if rank in (0, \"cpu\", \"cuda\"):\n",
    "\n",
    "train_error = val_error = test_error = float(\"NaN\")\n",
    "\n",
    "##workaround to get training output in DDP mode\n",
    "##outputs are slightly different, could be due to dropout or batchnorm?\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=model_parameters[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "##Get train error in eval mode\n",
    "train_error, train_out = evaluate(\n",
    "    train_loader, model, training_parameters[\"loss\"], 'cuda', out=True\n",
    ")\n",
    "print(\"Train Error: {:.5f}\".format(train_error))\n",
    "\n",
    "##Get val error\n",
    "if val_loader != None:\n",
    "    val_error, val_out = evaluate(\n",
    "        val_loader, model, training_parameters[\"loss\"], 'cuda', out=True\n",
    "    )\n",
    "    print(\"Val Error: {:.5f}\".format(val_error))\n",
    "\n",
    "##Get test error\n",
    "if test_loader != None:\n",
    "    test_error, test_out = evaluate(\n",
    "        test_loader, model, training_parameters[\"loss\"], 'cuda', out=True\n",
    "    )\n",
    "    print(\"Test Error: {:.5f}\".format(test_error))\n",
    "\n",
    "##Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d36f64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if job_parameters[\"save_model\"] == \"True\":\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"full_model\": model,\n",
    "        },\n",
    "        job_parameters[\"model_path\"],\n",
    "    )\n",
    "\n",
    "##Write outputs\n",
    "if job_parameters[\"write_output\"] == \"True\":\n",
    "\n",
    "    write_results(\n",
    "        train_out, str(job_parameters[\"job_name\"]) + \"_train_outputs.csv\"\n",
    "    )\n",
    "    if val_loader != None:\n",
    "        write_results(\n",
    "            val_out, str(job_parameters[\"job_name\"]) + \"_val_outputs.csv\"\n",
    "        )\n",
    "    if test_loader != None:\n",
    "        write_results(\n",
    "            test_out, str(job_parameters[\"job_name\"]) + \"_test_outputs.csv\"\n",
    "        )\n",
    "\n",
    "##Write out model performance to file\n",
    "error_values = np.array((train_error.cpu(), val_error.cpu(), test_error.cpu()))\n",
    "if job_parameters.get(\"write_error\") == \"True\":\n",
    "    np.savetxt(\n",
    "        job_parameters[\"job_name\"] + \"_errorvalues.csv\",\n",
    "        error_values[np.newaxis, ...],\n",
    "        delimiter=\",\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2dc19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, loss, job_parameters=None):\n",
    "\n",
    "    rank = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ##Loads predict dataset in one go, care needed for large datasets)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    ##Load saved model\n",
    "    assert os.path.exists(job_parameters[\"model_path\"]), \"Saved model not found\"\n",
    "    if str(rank) == \"cpu\":\n",
    "        saved = torch.load(\n",
    "            job_parameters[\"model_path\"], map_location=torch.device(\"cpu\")\n",
    "        )\n",
    "    else:\n",
    "        saved = torch.load(\n",
    "            job_parameters[\"model_path\"], map_location=torch.device(\"cuda\")\n",
    "        )\n",
    "    model = saved[\"full_model\"]\n",
    "    model = model.to(rank)\n",
    "    model_summary(model)\n",
    "\n",
    "    ##Get predictions\n",
    "    time_start = time.time()\n",
    "    test_error, test_out = evaluate(loader, model, loss, rank, out=True)\n",
    "    elapsed_time = time.time() - time_start\n",
    "\n",
    "    print(\"Evaluation time (s): {:.5f}\".format(elapsed_time))\n",
    "\n",
    "    ##Write output\n",
    "    if job_parameters[\"write_output\"] == \"True\":\n",
    "        write_results(\n",
    "            test_out, str(job_parameters[\"job_name\"]) + \"_predicted_outputs.csv\"\n",
    "        )\n",
    "\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec23d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length: 19472 val length: 0 test length: 0 unused length: 0 seed : 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "               Layer.Parameter    Param Tensor Shape              Param #\n",
      "--------------------------------------------------------------------------\n",
      "global_att_LAYER.global_mlp.0.weight             [64, 172]                11008\n",
      "global_att_LAYER.global_mlp.0.bias                  [64]                   64\n",
      "global_att_LAYER.global_mlp.1.weight              [64, 64]                 4096\n",
      "global_att_LAYER.global_mlp.1.bias                  [64]                   64\n",
      "global_att_LAYER.global_mlp.2.weight               [1, 64]                   64\n",
      "global_att_LAYER.global_mlp.2.bias                   [1]                    1\n",
      "global_att_LAYER.bn_list.0.lin.weight              [10, 64]                  640\n",
      "global_att_LAYER.bn_list.0.norm.weight                 [640]                  640\n",
      "global_att_LAYER.bn_list.0.norm.bias                 [640]                  640\n",
      "global_att_LAYER.bn_list.1.lin.weight              [10, 64]                  640\n",
      "global_att_LAYER.bn_list.1.norm.weight                 [640]                  640\n",
      "global_att_LAYER.bn_list.1.norm.bias                 [640]                  640\n",
      "global_att_LAYER.bn_list.2.lin.weight              [10, 64]                  640\n",
      "global_att_LAYER.bn_list.2.norm.weight                 [640]                  640\n",
      "global_att_LAYER.bn_list.2.norm.bias                 [640]                  640\n",
      "            encoder.emb_scaler                   [1]                    1\n",
      "            encoder.pos_scaler                   [1]                    1\n",
      "        encoder.pos_scaler_log                   [1]                    1\n",
      "encoder.embed.fc_mat2vec.weight            [512, 200]               102400\n",
      " encoder.embed.fc_mat2vec.bias                 [512]                  512\n",
      "     encoder.embed.cbfv.weight            [119, 200]                23800\n",
      "encoder.transformer_encoder.layers.0.self_attn.in_proj_weight           [1536, 512]               786432\n",
      "encoder.transformer_encoder.layers.0.self_attn.in_proj_bias                [1536]                 1536\n",
      "encoder.transformer_encoder.layers.0.self_attn.out_proj.weight            [512, 512]               262144\n",
      "encoder.transformer_encoder.layers.0.self_attn.out_proj.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.0.linear1.weight           [2048, 512]              1048576\n",
      "encoder.transformer_encoder.layers.0.linear1.bias                [2048]                 2048\n",
      "encoder.transformer_encoder.layers.0.linear2.weight           [512, 2048]              1048576\n",
      "encoder.transformer_encoder.layers.0.linear2.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.0.norm1.weight                 [512]                  512\n",
      "encoder.transformer_encoder.layers.0.norm1.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.0.norm2.weight                 [512]                  512\n",
      "encoder.transformer_encoder.layers.0.norm2.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.1.self_attn.in_proj_weight           [1536, 512]               786432\n",
      "encoder.transformer_encoder.layers.1.self_attn.in_proj_bias                [1536]                 1536\n",
      "encoder.transformer_encoder.layers.1.self_attn.out_proj.weight            [512, 512]               262144\n",
      "encoder.transformer_encoder.layers.1.self_attn.out_proj.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.1.linear1.weight           [2048, 512]              1048576\n",
      "encoder.transformer_encoder.layers.1.linear1.bias                [2048]                 2048\n",
      "encoder.transformer_encoder.layers.1.linear2.weight           [512, 2048]              1048576\n",
      "encoder.transformer_encoder.layers.1.linear2.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.1.norm1.weight                 [512]                  512\n",
      "encoder.transformer_encoder.layers.1.norm1.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.1.norm2.weight                 [512]                  512\n",
      "encoder.transformer_encoder.layers.1.norm2.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.2.self_attn.in_proj_weight           [1536, 512]               786432\n",
      "encoder.transformer_encoder.layers.2.self_attn.in_proj_bias                [1536]                 1536\n",
      "encoder.transformer_encoder.layers.2.self_attn.out_proj.weight            [512, 512]               262144\n",
      "encoder.transformer_encoder.layers.2.self_attn.out_proj.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.2.linear1.weight           [2048, 512]              1048576\n",
      "encoder.transformer_encoder.layers.2.linear1.bias                [2048]                 2048\n",
      "encoder.transformer_encoder.layers.2.linear2.weight           [512, 2048]              1048576\n",
      "encoder.transformer_encoder.layers.2.linear2.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.2.norm1.weight                 [512]                  512\n",
      "encoder.transformer_encoder.layers.2.norm1.bias                 [512]                  512\n",
      "encoder.transformer_encoder.layers.2.norm2.weight                 [512]                  512\n",
      "encoder.transformer_encoder.layers.2.norm2.bias                 [512]                  512\n",
      "        output_nn.fcs.0.weight           [1024, 512]               524288\n",
      "          output_nn.fcs.0.bias                [1024]                 1024\n",
      "        output_nn.fcs.1.weight           [512, 1024]               524288\n",
      "          output_nn.fcs.1.bias                 [512]                  512\n",
      "        output_nn.fcs.2.weight            [256, 512]               131072\n",
      "          output_nn.fcs.2.bias                 [256]                  256\n",
      "        output_nn.fcs.3.weight            [128, 256]                32768\n",
      "          output_nn.fcs.3.bias                 [128]                  128\n",
      "    output_nn.res_fcs.0.weight           [1024, 512]               524288\n",
      "    output_nn.res_fcs.1.weight           [512, 1024]               524288\n",
      "    output_nn.res_fcs.2.weight            [256, 512]               131072\n",
      "    output_nn.res_fcs.3.weight            [128, 256]                32768\n",
      "       output_nn.fc_out.weight             [64, 128]                 8192\n",
      "         output_nn.fc_out.bias                  [64]                   64\n",
      "       pre_lin_list_E.0.weight              [64, 50]                 3200\n",
      "         pre_lin_list_E.0.bias                  [64]                   64\n",
      "       pre_lin_list_N.0.weight             [64, 114]                 7296\n",
      "         pre_lin_list_N.0.bias                  [64]                   64\n",
      "                 conv_list.0.W            [128, 256]                32768\n",
      "               conv_list.0.att           [1, 4, 128]                  512\n",
      "              conv_list.0.bias                  [64]                   64\n",
      "        conv_list.0.bn1.weight                   [4]                    4\n",
      "          conv_list.0.bn1.bias                   [4]                    4\n",
      "                 conv_list.1.W            [128, 256]                32768\n",
      "               conv_list.1.att           [1, 4, 128]                  512\n",
      "              conv_list.1.bias                  [64]                   64\n",
      "        conv_list.1.bn1.weight                   [4]                    4\n",
      "          conv_list.1.bn1.bias                   [4]                    4\n",
      "                 conv_list.2.W            [128, 256]                32768\n",
      "               conv_list.2.att           [1, 4, 128]                  512\n",
      "              conv_list.2.bias                  [64]                   64\n",
      "        conv_list.2.bn1.weight                   [4]                    4\n",
      "          conv_list.2.bn1.bias                   [4]                    4\n",
      "                 conv_list.3.W            [128, 256]                32768\n",
      "               conv_list.3.att           [1, 4, 128]                  512\n",
      "              conv_list.3.bias                  [64]                   64\n",
      "        conv_list.3.bn1.weight                   [4]                    4\n",
      "          conv_list.3.bn1.bias                   [4]                    4\n",
      "                 conv_list.4.W            [128, 256]                32768\n",
      "               conv_list.4.att           [1, 4, 128]                  512\n",
      "              conv_list.4.bias                  [64]                   64\n",
      "        conv_list.4.bn1.weight                   [4]                    4\n",
      "          conv_list.4.bn1.bias                   [4]                    4\n",
      "                 conv_list.5.W            [128, 256]                32768\n",
      "               conv_list.5.att           [1, 4, 128]                  512\n",
      "              conv_list.5.bias                  [64]                   64\n",
      "        conv_list.5.bn1.weight                   [4]                    4\n",
      "          conv_list.5.bn1.bias                   [4]                    4\n",
      "                 conv_list.6.W            [128, 256]                32768\n",
      "               conv_list.6.att           [1, 4, 128]                  512\n",
      "              conv_list.6.bias                  [64]                   64\n",
      "        conv_list.6.bn1.weight                   [4]                    4\n",
      "          conv_list.6.bn1.bias                   [4]                    4\n",
      "                 conv_list.7.W            [128, 256]                32768\n",
      "               conv_list.7.att           [1, 4, 128]                  512\n",
      "              conv_list.7.bias                  [64]                   64\n",
      "        conv_list.7.bn1.weight                   [4]                    4\n",
      "          conv_list.7.bn1.bias                   [4]                    4\n",
      "                 conv_list.8.W            [128, 256]                32768\n",
      "               conv_list.8.att           [1, 4, 128]                  512\n",
      "              conv_list.8.bias                  [64]                   64\n",
      "        conv_list.8.bn1.weight                   [4]                    4\n",
      "          conv_list.8.bn1.bias                   [4]                    4\n",
      "                 conv_list.9.W            [128, 256]                32768\n",
      "               conv_list.9.att           [1, 4, 128]                  512\n",
      "              conv_list.9.bias                  [64]                   64\n",
      "        conv_list.9.bn1.weight                   [4]                    4\n",
      "          conv_list.9.bn1.bias                   [4]                    4\n",
      "                conv_list.10.W            [128, 256]                32768\n",
      "              conv_list.10.att           [1, 4, 128]                  512\n",
      "             conv_list.10.bias                  [64]                   64\n",
      "       conv_list.10.bn1.weight                   [4]                    4\n",
      "         conv_list.10.bn1.bias                   [4]                    4\n",
      "                conv_list.11.W            [128, 256]                32768\n",
      "              conv_list.11.att           [1, 4, 128]                  512\n",
      "             conv_list.11.bias                  [64]                   64\n",
      "       conv_list.11.bn1.weight                   [4]                    4\n",
      "         conv_list.11.bn1.bias                   [4]                    4\n",
      "                conv_list.12.W            [128, 256]                32768\n",
      "              conv_list.12.att           [1, 4, 128]                  512\n",
      "             conv_list.12.bias                  [64]                   64\n",
      "       conv_list.12.bn1.weight                   [4]                    4\n",
      "         conv_list.12.bn1.bias                   [4]                    4\n",
      "                conv_list.13.W            [128, 256]                32768\n",
      "              conv_list.13.att           [1, 4, 128]                  512\n",
      "             conv_list.13.bias                  [64]                   64\n",
      "       conv_list.13.bn1.weight                   [4]                    4\n",
      "         conv_list.13.bn1.bias                   [4]                    4\n",
      "                conv_list.14.W            [128, 256]                32768\n",
      "              conv_list.14.att           [1, 4, 128]                  512\n",
      "             conv_list.14.bias                  [64]                   64\n",
      "       conv_list.14.bn1.weight                   [4]                    4\n",
      "         conv_list.14.bn1.bias                   [4]                    4\n",
      "                conv_list.15.W            [128, 256]                32768\n",
      "              conv_list.15.att           [1, 4, 128]                  512\n",
      "             conv_list.15.bias                  [64]                   64\n",
      "       conv_list.15.bn1.weight                   [4]                    4\n",
      "         conv_list.15.bn1.bias                   [4]                    4\n",
      "                conv_list.16.W            [128, 256]                32768\n",
      "              conv_list.16.att           [1, 4, 128]                  512\n",
      "             conv_list.16.bias                  [64]                   64\n",
      "       conv_list.16.bn1.weight                   [4]                    4\n",
      "         conv_list.16.bn1.bias                   [4]                    4\n",
      "                conv_list.17.W            [128, 256]                32768\n",
      "              conv_list.17.att           [1, 4, 128]                  512\n",
      "             conv_list.17.bias                  [64]                   64\n",
      "       conv_list.17.bn1.weight                   [4]                    4\n",
      "         conv_list.17.bn1.bias                   [4]                    4\n",
      "                conv_list.18.W            [128, 256]                32768\n",
      "              conv_list.18.att           [1, 4, 128]                  512\n",
      "             conv_list.18.bias                  [64]                   64\n",
      "       conv_list.18.bn1.weight                   [4]                    4\n",
      "         conv_list.18.bn1.bias                   [4]                    4\n",
      "                conv_list.19.W            [128, 256]                32768\n",
      "              conv_list.19.att           [1, 4, 128]                  512\n",
      "             conv_list.19.bias                  [64]                   64\n",
      "       conv_list.19.bn1.weight                   [4]                    4\n",
      "         conv_list.19.bn1.bias                   [4]                    4\n",
      "          bn_list.0.lin.weight              [10, 64]                  640\n",
      "         bn_list.0.norm.weight                 [640]                  640\n",
      "           bn_list.0.norm.bias                 [640]                  640\n",
      "          bn_list.1.lin.weight              [10, 64]                  640\n",
      "         bn_list.1.norm.weight                 [640]                  640\n",
      "           bn_list.1.norm.bias                 [640]                  640\n",
      "          bn_list.2.lin.weight              [10, 64]                  640\n",
      "         bn_list.2.norm.weight                 [640]                  640\n",
      "           bn_list.2.norm.bias                 [640]                  640\n",
      "          bn_list.3.lin.weight              [10, 64]                  640\n",
      "         bn_list.3.norm.weight                 [640]                  640\n",
      "           bn_list.3.norm.bias                 [640]                  640\n",
      "          bn_list.4.lin.weight              [10, 64]                  640\n",
      "         bn_list.4.norm.weight                 [640]                  640\n",
      "           bn_list.4.norm.bias                 [640]                  640\n",
      "          bn_list.5.lin.weight              [10, 64]                  640\n",
      "         bn_list.5.norm.weight                 [640]                  640\n",
      "           bn_list.5.norm.bias                 [640]                  640\n",
      "          bn_list.6.lin.weight              [10, 64]                  640\n",
      "         bn_list.6.norm.weight                 [640]                  640\n",
      "           bn_list.6.norm.bias                 [640]                  640\n",
      "          bn_list.7.lin.weight              [10, 64]                  640\n",
      "         bn_list.7.norm.weight                 [640]                  640\n",
      "           bn_list.7.norm.bias                 [640]                  640\n",
      "          bn_list.8.lin.weight              [10, 64]                  640\n",
      "         bn_list.8.norm.weight                 [640]                  640\n",
      "           bn_list.8.norm.bias                 [640]                  640\n",
      "          bn_list.9.lin.weight              [10, 64]                  640\n",
      "         bn_list.9.norm.weight                 [640]                  640\n",
      "           bn_list.9.norm.bias                 [640]                  640\n",
      "         bn_list.10.lin.weight              [10, 64]                  640\n",
      "        bn_list.10.norm.weight                 [640]                  640\n",
      "          bn_list.10.norm.bias                 [640]                  640\n",
      "         bn_list.11.lin.weight              [10, 64]                  640\n",
      "        bn_list.11.norm.weight                 [640]                  640\n",
      "          bn_list.11.norm.bias                 [640]                  640\n",
      "         bn_list.12.lin.weight              [10, 64]                  640\n",
      "        bn_list.12.norm.weight                 [640]                  640\n",
      "          bn_list.12.norm.bias                 [640]                  640\n",
      "         bn_list.13.lin.weight              [10, 64]                  640\n",
      "        bn_list.13.norm.weight                 [640]                  640\n",
      "          bn_list.13.norm.bias                 [640]                  640\n",
      "         bn_list.14.lin.weight              [10, 64]                  640\n",
      "        bn_list.14.norm.weight                 [640]                  640\n",
      "          bn_list.14.norm.bias                 [640]                  640\n",
      "         bn_list.15.lin.weight              [10, 64]                  640\n",
      "        bn_list.15.norm.weight                 [640]                  640\n",
      "          bn_list.15.norm.bias                 [640]                  640\n",
      "         bn_list.16.lin.weight              [10, 64]                  640\n",
      "        bn_list.16.norm.weight                 [640]                  640\n",
      "          bn_list.16.norm.bias                 [640]                  640\n",
      "         bn_list.17.lin.weight              [10, 64]                  640\n",
      "        bn_list.17.norm.weight                 [640]                  640\n",
      "          bn_list.17.norm.bias                 [640]                  640\n",
      "         bn_list.18.lin.weight              [10, 64]                  640\n",
      "        bn_list.18.norm.weight                 [640]                  640\n",
      "          bn_list.18.norm.bias                 [640]                  640\n",
      "         bn_list.19.lin.weight              [10, 64]                  640\n",
      "        bn_list.19.norm.weight                 [640]                  640\n",
      "          bn_list.19.norm.bias                 [640]                  640\n",
      "                lin_out.weight               [1, 64]                   64\n",
      "                  lin_out.bias                   [1]                    1\n",
      "--------------------------------------------------------------------------\n",
      "Total params: 12756061\n",
      "Trainable params: 12732261\n",
      "Non-trainable params: 23800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time (s): 95.00240\n",
      "tensor(1.3122, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "database= get_dataset(cwd,0)\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    train_sampler,\n",
    "    train_dataset,\n",
    "    _,\n",
    "    _,\n",
    ") = loader_setup(\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    90,\n",
    "    database,\n",
    "    'cuda',\n",
    "    51,\n",
    "    0,\n",
    ")\n",
    "rank = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "assert os.path.exists(job_parameters[\"model_path\"]), \"Saved model not found\"\n",
    "if str(rank) == \"cpu\":\n",
    "    saved = torch.load(\n",
    "        job_parameters[\"model_path\"], map_location=torch.device(\"cpu\")\n",
    "    )\n",
    "else:\n",
    "    saved = torch.load(\n",
    "        job_parameters[\"model_path\"], map_location=torch.device(\"cuda\")\n",
    "    )\n",
    "model = saved[\"full_model\"]\n",
    "model = model.to(rank)\n",
    "model_summary(model)\n",
    "\n",
    "##Get predictions\n",
    "time_start = time.time()\n",
    "test_error, test_out = evaluate(train_loader, model, training_parameters[\"loss\"], rank, out=True)\n",
    "elapsed_time = time.time() - time_start\n",
    "\n",
    "print(\"Evaluation time (s): {:.5f}\".format(elapsed_time))\n",
    "\n",
    "print(test_error)\n",
    "\n",
    "##Write output\n",
    "if job_parameters[\"write_output\"] == \"True\":\n",
    "    write_results(\n",
    "        test_out, str(job_parameters[\"job_name\"]) + \"Li_BG.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e10d5e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_hard_poscar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata_hard_poscar\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_hard_poscar' is not defined"
     ]
    }
   ],
   "source": [
    "data_hard_poscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde8e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
